# Convolutional Neural Network 

Реализация сверточной нейронной сети с нуля на NumPy для классификации датасета MNIST (распознавание рукописных цифр).

Проект реализует полный цикл обучения без использования PyTorch или TensorFlow для модели, включая:

- прямой проход (forward pass)
- обратное распространение ошибки (backpropagation)
- оптимизацию с Momentum
- свёртки через im2col
- стабилизацию обучения
- контроль переобучения


## Архитектура модели

Input: (1, 28, 28)  
→ Conv2D (16, 3×3)  
→ LeakyReLU  
→ MaxPool2D (2×2)  
→ Flatten  
→ Linear (2704 → 128)  
→ LeakyReLU  
→ Linear (128 → 10)  
→ Softmax  


## Возможности

- Реализация Conv2D через im2col
- Полный backprop для всех слоёв
- Momentum optimizer
- Gradient clipping
- Reduce LR on plateau
- Early stopping
- Warmup learning rate
- Confusion matrix
- Анализ ошибок модели


## Требования

Python 3.8+

Установленные библиотеки:

pip install numpy matplotlib tqdm tensorflow


## Использование

Открыть и запустить ноутбук:

CNN_model.ipynb

Модель обучается до достижения целевой accuracy или срабатывания early stopping.


## Результаты

- Validation accuracy: ~96%
- Test accuracy: ~96%
- Confusion matrix показывает выраженную диагональ
- Основные ошибки — визуально похожие цифры (например 4 и 9)


## Технические детали

### Реализация свёртки через im2col

Свёртка реализована без вложенных циклов по пространственным координатам.  
Вход преобразуется в матричный вид (im2col), после чего операция свёртки выполняется как матричное умножение.


### Численная стабилизация softmax

Для предотвращения переполнения экспоненты используется смещение логитов:

shifted = logits - max(logits)

Это делает вычисление softmax численно стабильным.


## Решённые проблемы

1. Dead ReLU  
Использован LeakyReLU для предотвращения зануления градиента.

2. Численная нестабильность логитов  
Добавлено вычитание максимума перед softmax.

3. Взрыв градиентов  
Реализован gradient clipping по норме.

4. Плохая сходимость  
Добавлен Reduce LR on plateau.

5. Переобучение  
Реализован early stopping по validation accuracy.

6. Низкая скорость свёртки  
Наивная реализация заменена на im2col + матричное умножение.


## Ограничения

- Нет GPU-ускорения
- Нет BatchNorm или Dropout
- Реализация ориентирована на образовательные цели


## Возможные улучшения

- Добавить второй сверточный слой
- Реализовать BatchNorm
- Реализовать Adam optimizer
- Сравнить производительность с PyTorch


## Автор

Дмитрий Филатов (2026)
